{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "cellId": "91cfx45ovsit51f2dxx9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!c1.32\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import scipy\n",
    "import plotly.express as px\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "cellId": "bsqw5zi2wqnc415dtsh6ov"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "cellId": "ua6mrifjb1jchi8smrng7m"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/jupyter/mnt/s3/hack-data/hse/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "cellId": "y3tavak779b6ghfbys4yv"
   },
   "outputs": [],
   "source": [
    "train = train.drop([train.columns[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "cellId": "62kql9ax2j7bl3yds1xew"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "# %pip install razdel\n",
    "import re\n",
    "import pymorphy2\n",
    "import razdel\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^а-яА-Я\\s]', '', text)\n",
    "\n",
    "    # Tokenize text\n",
    "    tokens = [token.text for token in razdel.tokenize(text)]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatize tokens\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    tokens = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "cellId": "phgse6771ejhboet8clc1a"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "train['clean_text'] = train['sentence'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "cellId": "d73a4f0074l0r4jubnpr11j"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "train.to_csv('last_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "cellId": "b7vtj48nc4hgaumtabymq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence          0\n",
       "1category         0\n",
       "2category     18362\n",
       "sentiment         0\n",
       "clean_text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "9xjpvbz910982ml89xel7t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "−    10192\n",
       "+     6262\n",
       "?     2907\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "cellId": "rzzjtjp8funxx3b9jf1hn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>1category</th>\n",
       "      <th>2category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>При этом всегда получал качественные услуги.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "      <td>получать качественный услуга</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Не вижу, за что хотя бы 2 поставить, сервис на 1!</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "      <td>видеть хотя поставить сервис</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Вот так \"Мой любимый\" банк МКБ меня обманул.</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "      <td>любимый банк мкб обмануть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Отвратительное отношение к клиентам.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "      <td>отвратительный отношение клиент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Всегда в любое время дня и ночи помогут, ответ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "      <td>любой время день ночь помочь ответить решить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19356</th>\n",
       "      <td>Никогда и ни в коем случае не открывайте счет ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "      <td>кой случай открывать счёт недостойный доверие ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19357</th>\n",
       "      <td>ТИ откровенно забили на качество и развивают с...</td>\n",
       "      <td>Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "      <td>ти откровенно забить качество развивать свой м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19358</th>\n",
       "      <td>Я считаю, это прорыв и лидерство финансовых ус...</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "      <td>считать это прорыв лидерство финансовый услуга...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>Писал мужчина очень доходчиво, не финансовым я...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "      <td>писать мужчина очень доходчиво финансовый язык...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19360</th>\n",
       "      <td>Данная ситуация меня сильно выбила из колеи, и...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "      <td>дать ситуация сильно выбить колея вместо заним...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19361 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  ...                                         clean_text\n",
       "0           При этом всегда получал качественные услуги.  ...                       получать качественный услуга\n",
       "1      Не вижу, за что хотя бы 2 поставить, сервис на 1!  ...                       видеть хотя поставить сервис\n",
       "2           Вот так \"Мой любимый\" банк МКБ меня обманул.  ...                          любимый банк мкб обмануть\n",
       "3                   Отвратительное отношение к клиентам.  ...                    отвратительный отношение клиент\n",
       "4      Всегда в любое время дня и ночи помогут, ответ...  ...       любой время день ночь помочь ответить решить\n",
       "...                                                  ...  ...                                                ...\n",
       "19356  Никогда и ни в коем случае не открывайте счет ...  ...  кой случай открывать счёт недостойный доверие ...\n",
       "19357  ТИ откровенно забили на качество и развивают с...  ...  ти откровенно забить качество развивать свой м...\n",
       "19358  Я считаю, это прорыв и лидерство финансовых ус...  ...  считать это прорыв лидерство финансовый услуга...\n",
       "19359  Писал мужчина очень доходчиво, не финансовым я...  ...  писать мужчина очень доходчиво финансовый язык...\n",
       "19360  Данная ситуация меня сильно выбила из колеи, и...  ...  дать ситуация сильно выбить колея вместо заним...\n",
       "\n",
       "[19361 rows x 5 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "cellId": "iv7y0f4jq1o42smsx272gr"
   },
   "outputs": [],
   "source": [
    "labels = ['1category', '2category', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "cellId": "1md95sjubkuz7p2h9f7ogb"
   },
   "outputs": [],
   "source": [
    "# Sentiment classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = train['clean_text']\n",
    "y = train['sentiment']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "cellId": "fevl62ej367b2gp7d7aa18"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "cellId": "lvxiu3gytghbr5fiflj3g"
   },
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier(objective='multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "cellId": "yeqftxkpugq8wasjpgs3fv"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "cellId": "qb1a6v3o7q4xb1zlk5gmu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "cellId": "7lxzqh3mqfhae0nudkndw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score base xgb ovr:  0.8481686299354066\n"
     ]
    }
   ],
   "source": [
    "print('roc_auc_score base xgb ovr: ', roc_auc_score(y_test, classifier.predict_proba(X_test), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "cellId": "y3ug4sq9jrjo3q3c84d4"
   },
   "outputs": [],
   "source": [
    "# With embedding features\n",
    "# %pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "cellId": "aucwmysiksp7kskc9qwo3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "# Define a function to extract sentence embeddings from a DataFrame\n",
    "def get_sentence_embeddings(df, text_column='text'):\n",
    "    # Tokenize the text column and convert to input IDs\n",
    "    encoded_input = tokenizer(list(df[text_column]), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the model's outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "\n",
    "    # Get the embeddings for each sentence\n",
    "    embeddings = mean_pooling(outputs, encoded_input['attention_mask'])\n",
    "\n",
    "    # Create a new DataFrame with the embeddings\n",
    "    embedding_cols = [f\"embedding_{i}\" for i in range(embeddings.shape[1])]\n",
    "    embeddings_df = pd.DataFrame(embeddings.numpy(), columns=embedding_cols)\n",
    "\n",
    "    # Combine the original DataFrame with the new DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    embeddings_df.reset_index(drop=True, inplace=True)\n",
    "    combined_df = pd.concat([df, embeddings_df], axis=1)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "cellId": "pritbije8tg11ykq6r8wwyj"
   },
   "outputs": [],
   "source": [
    "X_best_emb = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "cellId": "njhm1a77ld8voo21486n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              clean_text  ...  embedding_767\n",
      "0                           получать качественный услуга  ...      -0.006486\n",
      "1                           видеть хотя поставить сервис  ...      -0.059996\n",
      "2                              любимый банк мкб обмануть  ...      -0.043312\n",
      "3                        отвратительный отношение клиент  ...      -0.007149\n",
      "4           любой время день ночь помочь ответить решить  ...      -0.077008\n",
      "...                                                  ...  ...            ...\n",
      "19356  кой случай открывать счёт недостойный доверие ...  ...      -0.004653\n",
      "19357  ти откровенно забить качество развивать свой м...  ...      -0.018135\n",
      "19358  считать это прорыв лидерство финансовый услуга...  ...       0.029666\n",
      "19359  писать мужчина очень доходчиво финансовый язык...  ...      -0.094332\n",
      "19360  дать ситуация сильно выбить колея вместо заним...  ...      -0.005209\n",
      "\n",
      "[19361 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "X_best_emb = get_sentence_embeddings(X_best_emb, 'clean_text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "cellId": "mcs3d3lcpziuw0johw0iz"
   },
   "outputs": [],
   "source": [
    "# #!c1.32\n",
    "# X_best_emb.to_csv('best_emb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "cellId": "ah7i27e15sj1yvarqvk7xuj"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "X_best_emb = X_best_emb.drop('clean_text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "cellId": "batqk0i768wvwaebs467a"
   },
   "outputs": [],
   "source": [
    "# def generate_embeddings(text_series):\n",
    "#     # Tokenize text\n",
    "#     input_ids = tokenizer.batch_encode_plus(text_series.tolist(),\n",
    "#                                              padding=True,\n",
    "#                                              truncation=True,\n",
    "#                                              return_tensors='pt')\n",
    "#     # Generate embeddings\n",
    "#     with torch.no_grad():\n",
    "#         last_hidden_states = model(input_ids['input_ids'])[0]  # Last hidden state of the top layer\n",
    "#         sentence_embeddings = torch.mean(last_hidden_states, dim=1).squeeze().numpy()\n",
    "#     # Return a DataFrame with the sentence embeddings\n",
    "#     return pd.DataFrame(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "cellId": "sasyp31nbzhmrl34xxzch"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>embedding_11</th>\n",
       "      <th>embedding_12</th>\n",
       "      <th>embedding_13</th>\n",
       "      <th>embedding_14</th>\n",
       "      <th>embedding_15</th>\n",
       "      <th>embedding_16</th>\n",
       "      <th>embedding_17</th>\n",
       "      <th>embedding_18</th>\n",
       "      <th>embedding_19</th>\n",
       "      <th>embedding_20</th>\n",
       "      <th>embedding_21</th>\n",
       "      <th>embedding_22</th>\n",
       "      <th>embedding_23</th>\n",
       "      <th>embedding_24</th>\n",
       "      <th>embedding_25</th>\n",
       "      <th>embedding_26</th>\n",
       "      <th>embedding_27</th>\n",
       "      <th>embedding_28</th>\n",
       "      <th>embedding_29</th>\n",
       "      <th>embedding_30</th>\n",
       "      <th>embedding_31</th>\n",
       "      <th>embedding_32</th>\n",
       "      <th>embedding_33</th>\n",
       "      <th>embedding_34</th>\n",
       "      <th>embedding_35</th>\n",
       "      <th>embedding_36</th>\n",
       "      <th>embedding_37</th>\n",
       "      <th>embedding_38</th>\n",
       "      <th>embedding_39</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_728</th>\n",
       "      <th>embedding_729</th>\n",
       "      <th>embedding_730</th>\n",
       "      <th>embedding_731</th>\n",
       "      <th>embedding_732</th>\n",
       "      <th>embedding_733</th>\n",
       "      <th>embedding_734</th>\n",
       "      <th>embedding_735</th>\n",
       "      <th>embedding_736</th>\n",
       "      <th>embedding_737</th>\n",
       "      <th>embedding_738</th>\n",
       "      <th>embedding_739</th>\n",
       "      <th>embedding_740</th>\n",
       "      <th>embedding_741</th>\n",
       "      <th>embedding_742</th>\n",
       "      <th>embedding_743</th>\n",
       "      <th>embedding_744</th>\n",
       "      <th>embedding_745</th>\n",
       "      <th>embedding_746</th>\n",
       "      <th>embedding_747</th>\n",
       "      <th>embedding_748</th>\n",
       "      <th>embedding_749</th>\n",
       "      <th>embedding_750</th>\n",
       "      <th>embedding_751</th>\n",
       "      <th>embedding_752</th>\n",
       "      <th>embedding_753</th>\n",
       "      <th>embedding_754</th>\n",
       "      <th>embedding_755</th>\n",
       "      <th>embedding_756</th>\n",
       "      <th>embedding_757</th>\n",
       "      <th>embedding_758</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.241628</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>-0.029144</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>-0.067558</td>\n",
       "      <td>0.036489</td>\n",
       "      <td>-0.035385</td>\n",
       "      <td>-0.098121</td>\n",
       "      <td>-0.001461</td>\n",
       "      <td>0.052536</td>\n",
       "      <td>-0.034371</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.121725</td>\n",
       "      <td>-0.049692</td>\n",
       "      <td>-0.099421</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.118351</td>\n",
       "      <td>0.088236</td>\n",
       "      <td>0.068724</td>\n",
       "      <td>0.054692</td>\n",
       "      <td>-0.070634</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>-0.083231</td>\n",
       "      <td>-0.097430</td>\n",
       "      <td>-0.074589</td>\n",
       "      <td>0.038302</td>\n",
       "      <td>0.067926</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.078138</td>\n",
       "      <td>0.176265</td>\n",
       "      <td>-0.015241</td>\n",
       "      <td>-0.051467</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.073454</td>\n",
       "      <td>-0.018251</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>-0.260475</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077746</td>\n",
       "      <td>0.057607</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.118187</td>\n",
       "      <td>0.062028</td>\n",
       "      <td>-0.029584</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>-0.051511</td>\n",
       "      <td>-0.109085</td>\n",
       "      <td>-0.134220</td>\n",
       "      <td>0.067069</td>\n",
       "      <td>-0.072714</td>\n",
       "      <td>-0.069804</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>-0.034886</td>\n",
       "      <td>0.064578</td>\n",
       "      <td>0.091832</td>\n",
       "      <td>0.066961</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>-0.050085</td>\n",
       "      <td>0.035246</td>\n",
       "      <td>-0.025142</td>\n",
       "      <td>-0.015900</td>\n",
       "      <td>0.049331</td>\n",
       "      <td>-0.112987</td>\n",
       "      <td>0.040169</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.075411</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.092569</td>\n",
       "      <td>0.053626</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.064224</td>\n",
       "      <td>-0.028944</td>\n",
       "      <td>-0.001428</td>\n",
       "      <td>0.048150</td>\n",
       "      <td>-0.006486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.121184</td>\n",
       "      <td>-0.021057</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.081309</td>\n",
       "      <td>-0.043712</td>\n",
       "      <td>0.052399</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.025378</td>\n",
       "      <td>-0.046738</td>\n",
       "      <td>0.094740</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>-0.084529</td>\n",
       "      <td>-0.005280</td>\n",
       "      <td>0.084593</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>0.076434</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>-0.042510</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>-0.032506</td>\n",
       "      <td>-0.050887</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.062467</td>\n",
       "      <td>0.066549</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>0.099447</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>-0.020750</td>\n",
       "      <td>0.044826</td>\n",
       "      <td>0.063929</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>0.014999</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>-0.186087</td>\n",
       "      <td>0.044810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054326</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>-0.032734</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.048294</td>\n",
       "      <td>0.073611</td>\n",
       "      <td>-0.066328</td>\n",
       "      <td>0.034614</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>-0.088454</td>\n",
       "      <td>0.080578</td>\n",
       "      <td>-0.035522</td>\n",
       "      <td>0.019205</td>\n",
       "      <td>0.030349</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>0.055587</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.025840</td>\n",
       "      <td>-0.008856</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.055406</td>\n",
       "      <td>0.048858</td>\n",
       "      <td>-0.081276</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>-0.039150</td>\n",
       "      <td>0.163801</td>\n",
       "      <td>-0.017198</td>\n",
       "      <td>0.036937</td>\n",
       "      <td>0.058067</td>\n",
       "      <td>-0.009065</td>\n",
       "      <td>0.043891</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.059182</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>-0.059996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.075674</td>\n",
       "      <td>-0.020425</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.029522</td>\n",
       "      <td>0.029704</td>\n",
       "      <td>-0.042396</td>\n",
       "      <td>0.039335</td>\n",
       "      <td>0.111208</td>\n",
       "      <td>-0.007800</td>\n",
       "      <td>0.042671</td>\n",
       "      <td>0.053530</td>\n",
       "      <td>0.086570</td>\n",
       "      <td>0.038352</td>\n",
       "      <td>0.020343</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>-0.047338</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>-0.072279</td>\n",
       "      <td>-0.025455</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.038113</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.064831</td>\n",
       "      <td>0.094317</td>\n",
       "      <td>-0.028070</td>\n",
       "      <td>-0.030072</td>\n",
       "      <td>0.091732</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>-0.051505</td>\n",
       "      <td>-0.051563</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>-0.131399</td>\n",
       "      <td>-0.037943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>-0.067960</td>\n",
       "      <td>-0.031858</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.010518</td>\n",
       "      <td>-0.015273</td>\n",
       "      <td>0.022009</td>\n",
       "      <td>-0.008994</td>\n",
       "      <td>-0.013429</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>0.108474</td>\n",
       "      <td>-0.001345</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>0.048841</td>\n",
       "      <td>0.051880</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.034893</td>\n",
       "      <td>0.055792</td>\n",
       "      <td>-0.002181</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>-0.055997</td>\n",
       "      <td>0.133109</td>\n",
       "      <td>-0.020609</td>\n",
       "      <td>0.081528</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.119111</td>\n",
       "      <td>-0.045735</td>\n",
       "      <td>-0.121504</td>\n",
       "      <td>-0.031943</td>\n",
       "      <td>-0.004047</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>0.075990</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.063491</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>0.081379</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>-0.043312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055516</td>\n",
       "      <td>0.165853</td>\n",
       "      <td>-0.019206</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>0.176546</td>\n",
       "      <td>-0.065510</td>\n",
       "      <td>0.083418</td>\n",
       "      <td>-0.041515</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>-0.026218</td>\n",
       "      <td>-0.118382</td>\n",
       "      <td>-0.019871</td>\n",
       "      <td>0.078905</td>\n",
       "      <td>-0.019787</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>-0.038124</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.122164</td>\n",
       "      <td>0.023543</td>\n",
       "      <td>0.085979</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>-0.084974</td>\n",
       "      <td>-0.041781</td>\n",
       "      <td>0.146133</td>\n",
       "      <td>0.043074</td>\n",
       "      <td>0.054345</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.183745</td>\n",
       "      <td>-0.054708</td>\n",
       "      <td>-0.025231</td>\n",
       "      <td>0.098661</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.069814</td>\n",
       "      <td>0.069698</td>\n",
       "      <td>-0.167185</td>\n",
       "      <td>0.067296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120063</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>-0.114192</td>\n",
       "      <td>-0.006113</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>-0.012574</td>\n",
       "      <td>0.095878</td>\n",
       "      <td>-0.003479</td>\n",
       "      <td>0.181798</td>\n",
       "      <td>-0.037902</td>\n",
       "      <td>-0.051318</td>\n",
       "      <td>0.066170</td>\n",
       "      <td>-0.097861</td>\n",
       "      <td>-0.054045</td>\n",
       "      <td>0.089349</td>\n",
       "      <td>0.093794</td>\n",
       "      <td>-0.039893</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>0.073508</td>\n",
       "      <td>0.041982</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>-0.021435</td>\n",
       "      <td>0.071309</td>\n",
       "      <td>0.078042</td>\n",
       "      <td>-0.082248</td>\n",
       "      <td>-0.039738</td>\n",
       "      <td>0.035065</td>\n",
       "      <td>-0.095385</td>\n",
       "      <td>-0.039955</td>\n",
       "      <td>-0.023927</td>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.077772</td>\n",
       "      <td>-0.056700</td>\n",
       "      <td>-0.010030</td>\n",
       "      <td>0.039664</td>\n",
       "      <td>0.067684</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>-0.010839</td>\n",
       "      <td>-0.008864</td>\n",
       "      <td>-0.007149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.098936</td>\n",
       "      <td>-0.019082</td>\n",
       "      <td>-0.048949</td>\n",
       "      <td>-0.088563</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>0.067510</td>\n",
       "      <td>-0.018606</td>\n",
       "      <td>-0.032498</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.106345</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>-0.019002</td>\n",
       "      <td>-0.109740</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.035395</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>0.055502</td>\n",
       "      <td>0.072337</td>\n",
       "      <td>0.066895</td>\n",
       "      <td>-0.070712</td>\n",
       "      <td>-0.061158</td>\n",
       "      <td>0.033087</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>-0.060536</td>\n",
       "      <td>-0.075645</td>\n",
       "      <td>-0.053182</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.102579</td>\n",
       "      <td>0.025283</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>-0.037630</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>0.048532</td>\n",
       "      <td>-0.047140</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>-0.110448</td>\n",
       "      <td>0.057402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082282</td>\n",
       "      <td>-0.045841</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.064587</td>\n",
       "      <td>0.154941</td>\n",
       "      <td>-0.088713</td>\n",
       "      <td>-0.060990</td>\n",
       "      <td>0.122343</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>-0.070383</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.074127</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.051743</td>\n",
       "      <td>-0.040039</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>-0.012542</td>\n",
       "      <td>-0.038191</td>\n",
       "      <td>-0.058006</td>\n",
       "      <td>-0.049079</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>0.105425</td>\n",
       "      <td>-0.055338</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>-0.135738</td>\n",
       "      <td>0.032607</td>\n",
       "      <td>0.044237</td>\n",
       "      <td>-0.034184</td>\n",
       "      <td>-0.035729</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.059493</td>\n",
       "      <td>-0.073302</td>\n",
       "      <td>-0.077008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19356</th>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.190487</td>\n",
       "      <td>-0.016859</td>\n",
       "      <td>0.129469</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.028348</td>\n",
       "      <td>0.103735</td>\n",
       "      <td>-0.140008</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>-0.020262</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>0.047823</td>\n",
       "      <td>0.158538</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.134618</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>0.174324</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.070812</td>\n",
       "      <td>-0.042047</td>\n",
       "      <td>0.059702</td>\n",
       "      <td>-0.043955</td>\n",
       "      <td>0.015048</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.148943</td>\n",
       "      <td>0.090439</td>\n",
       "      <td>0.101152</td>\n",
       "      <td>0.027369</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>-0.044023</td>\n",
       "      <td>-0.010375</td>\n",
       "      <td>0.162489</td>\n",
       "      <td>0.089912</td>\n",
       "      <td>-0.094445</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>-0.111342</td>\n",
       "      <td>0.058115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.088034</td>\n",
       "      <td>-0.130248</td>\n",
       "      <td>0.045140</td>\n",
       "      <td>0.056150</td>\n",
       "      <td>-0.021118</td>\n",
       "      <td>-0.073407</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.099365</td>\n",
       "      <td>-0.019841</td>\n",
       "      <td>0.054088</td>\n",
       "      <td>0.172221</td>\n",
       "      <td>-0.076232</td>\n",
       "      <td>-0.043356</td>\n",
       "      <td>0.040483</td>\n",
       "      <td>0.064913</td>\n",
       "      <td>-0.008509</td>\n",
       "      <td>0.107167</td>\n",
       "      <td>0.161598</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>-0.008049</td>\n",
       "      <td>-0.055603</td>\n",
       "      <td>0.222658</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>-0.004490</td>\n",
       "      <td>-0.069614</td>\n",
       "      <td>-0.081410</td>\n",
       "      <td>-0.032854</td>\n",
       "      <td>-0.128941</td>\n",
       "      <td>-0.061860</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>0.035053</td>\n",
       "      <td>0.090665</td>\n",
       "      <td>-0.041925</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.109257</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>-0.004653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19357</th>\n",
       "      <td>0.032032</td>\n",
       "      <td>0.061537</td>\n",
       "      <td>-0.019264</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.050557</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>-0.102295</td>\n",
       "      <td>-0.006774</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.049832</td>\n",
       "      <td>0.120977</td>\n",
       "      <td>-0.032588</td>\n",
       "      <td>0.223147</td>\n",
       "      <td>0.087384</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>-0.017253</td>\n",
       "      <td>0.113171</td>\n",
       "      <td>-0.064779</td>\n",
       "      <td>0.040170</td>\n",
       "      <td>0.066414</td>\n",
       "      <td>-0.055323</td>\n",
       "      <td>0.102652</td>\n",
       "      <td>-0.046222</td>\n",
       "      <td>-0.042363</td>\n",
       "      <td>-0.073428</td>\n",
       "      <td>0.136881</td>\n",
       "      <td>0.061939</td>\n",
       "      <td>0.117052</td>\n",
       "      <td>-0.020631</td>\n",
       "      <td>0.084884</td>\n",
       "      <td>0.082405</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>0.108797</td>\n",
       "      <td>0.083144</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.036466</td>\n",
       "      <td>-0.109827</td>\n",
       "      <td>0.077345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114720</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>-0.061978</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>-0.008894</td>\n",
       "      <td>0.135873</td>\n",
       "      <td>-0.046067</td>\n",
       "      <td>-0.027038</td>\n",
       "      <td>0.013262</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>-0.016292</td>\n",
       "      <td>0.104308</td>\n",
       "      <td>-0.086204</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>-0.010030</td>\n",
       "      <td>-0.032328</td>\n",
       "      <td>-0.059210</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>0.060439</td>\n",
       "      <td>-0.042580</td>\n",
       "      <td>0.051341</td>\n",
       "      <td>-0.052456</td>\n",
       "      <td>-0.090050</td>\n",
       "      <td>0.058605</td>\n",
       "      <td>-0.007622</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>0.072451</td>\n",
       "      <td>-0.022359</td>\n",
       "      <td>-0.099756</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.065365</td>\n",
       "      <td>-0.026523</td>\n",
       "      <td>-0.043882</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.036737</td>\n",
       "      <td>-0.109647</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.070602</td>\n",
       "      <td>-0.049907</td>\n",
       "      <td>-0.018135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19358</th>\n",
       "      <td>-0.042555</td>\n",
       "      <td>-0.036387</td>\n",
       "      <td>-0.016100</td>\n",
       "      <td>-0.049482</td>\n",
       "      <td>-0.021552</td>\n",
       "      <td>-0.012359</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.108123</td>\n",
       "      <td>0.100553</td>\n",
       "      <td>0.072379</td>\n",
       "      <td>0.062237</td>\n",
       "      <td>-0.018137</td>\n",
       "      <td>-0.182154</td>\n",
       "      <td>0.164171</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>-0.067014</td>\n",
       "      <td>0.057596</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>-0.033289</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.071176</td>\n",
       "      <td>-0.106822</td>\n",
       "      <td>0.023198</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.056661</td>\n",
       "      <td>0.041402</td>\n",
       "      <td>-0.015770</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.051816</td>\n",
       "      <td>0.013990</td>\n",
       "      <td>0.061542</td>\n",
       "      <td>-0.019067</td>\n",
       "      <td>-0.077444</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>-0.092869</td>\n",
       "      <td>-0.096613</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>-0.004086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106031</td>\n",
       "      <td>-0.031616</td>\n",
       "      <td>-0.083514</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.052532</td>\n",
       "      <td>-0.353515</td>\n",
       "      <td>0.139265</td>\n",
       "      <td>-0.103176</td>\n",
       "      <td>-0.117686</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>0.121815</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>-0.075879</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.113561</td>\n",
       "      <td>-0.033536</td>\n",
       "      <td>0.025928</td>\n",
       "      <td>-0.064397</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>-0.101179</td>\n",
       "      <td>0.112897</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>-0.069024</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>-0.004581</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>0.036679</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>0.056693</td>\n",
       "      <td>0.017727</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.029666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>-0.046310</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>-0.013776</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>0.031498</td>\n",
       "      <td>0.084283</td>\n",
       "      <td>-0.063685</td>\n",
       "      <td>0.054541</td>\n",
       "      <td>0.034563</td>\n",
       "      <td>-0.023627</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.064758</td>\n",
       "      <td>0.198033</td>\n",
       "      <td>0.103672</td>\n",
       "      <td>-0.044455</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.193940</td>\n",
       "      <td>-0.007223</td>\n",
       "      <td>0.041154</td>\n",
       "      <td>-0.015628</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>-0.061298</td>\n",
       "      <td>-0.094090</td>\n",
       "      <td>-0.092930</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>-0.009801</td>\n",
       "      <td>0.046079</td>\n",
       "      <td>0.140374</td>\n",
       "      <td>0.085737</td>\n",
       "      <td>0.025180</td>\n",
       "      <td>-0.012207</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>-0.055421</td>\n",
       "      <td>-0.014615</td>\n",
       "      <td>-0.015750</td>\n",
       "      <td>-0.176912</td>\n",
       "      <td>-0.116083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065639</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>-0.086146</td>\n",
       "      <td>-0.019464</td>\n",
       "      <td>0.121880</td>\n",
       "      <td>-0.011878</td>\n",
       "      <td>-0.096177</td>\n",
       "      <td>0.033733</td>\n",
       "      <td>-0.025875</td>\n",
       "      <td>-0.063330</td>\n",
       "      <td>0.051564</td>\n",
       "      <td>0.079271</td>\n",
       "      <td>-0.016830</td>\n",
       "      <td>0.089070</td>\n",
       "      <td>0.132223</td>\n",
       "      <td>0.098517</td>\n",
       "      <td>-0.090881</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.035420</td>\n",
       "      <td>-0.034058</td>\n",
       "      <td>0.096813</td>\n",
       "      <td>-0.157179</td>\n",
       "      <td>0.214725</td>\n",
       "      <td>-0.185385</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>0.095712</td>\n",
       "      <td>-0.164586</td>\n",
       "      <td>0.017719</td>\n",
       "      <td>-0.113055</td>\n",
       "      <td>0.015780</td>\n",
       "      <td>0.051612</td>\n",
       "      <td>-0.016716</td>\n",
       "      <td>0.093506</td>\n",
       "      <td>0.087237</td>\n",
       "      <td>-0.039637</td>\n",
       "      <td>0.093844</td>\n",
       "      <td>0.117690</td>\n",
       "      <td>0.068180</td>\n",
       "      <td>-0.032256</td>\n",
       "      <td>-0.094332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19360</th>\n",
       "      <td>0.038412</td>\n",
       "      <td>0.145606</td>\n",
       "      <td>-0.019342</td>\n",
       "      <td>-0.043872</td>\n",
       "      <td>0.018586</td>\n",
       "      <td>0.115227</td>\n",
       "      <td>0.076486</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.147701</td>\n",
       "      <td>0.034751</td>\n",
       "      <td>0.116303</td>\n",
       "      <td>0.105893</td>\n",
       "      <td>0.053160</td>\n",
       "      <td>-0.101956</td>\n",
       "      <td>-0.092471</td>\n",
       "      <td>-0.046563</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>0.117087</td>\n",
       "      <td>0.123052</td>\n",
       "      <td>-0.005108</td>\n",
       "      <td>-0.028695</td>\n",
       "      <td>-0.021444</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>0.025875</td>\n",
       "      <td>-0.052757</td>\n",
       "      <td>-0.025217</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.143321</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.134172</td>\n",
       "      <td>0.029890</td>\n",
       "      <td>-0.042052</td>\n",
       "      <td>-0.016633</td>\n",
       "      <td>0.041523</td>\n",
       "      <td>0.026531</td>\n",
       "      <td>0.065207</td>\n",
       "      <td>0.025967</td>\n",
       "      <td>-0.121132</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138994</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>0.095408</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>-0.119775</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.031923</td>\n",
       "      <td>-0.042352</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>-0.010925</td>\n",
       "      <td>-0.015605</td>\n",
       "      <td>0.065187</td>\n",
       "      <td>0.034215</td>\n",
       "      <td>0.067443</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>0.070159</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>0.168811</td>\n",
       "      <td>-0.039583</td>\n",
       "      <td>0.052872</td>\n",
       "      <td>0.051064</td>\n",
       "      <td>-0.034162</td>\n",
       "      <td>-0.044080</td>\n",
       "      <td>-0.048147</td>\n",
       "      <td>-0.129324</td>\n",
       "      <td>0.043325</td>\n",
       "      <td>-0.032400</td>\n",
       "      <td>0.101889</td>\n",
       "      <td>-0.108100</td>\n",
       "      <td>-0.146096</td>\n",
       "      <td>-0.011788</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>-0.030468</td>\n",
       "      <td>0.054793</td>\n",
       "      <td>0.071238</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>-0.005209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19361 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embedding_0  embedding_1  ...  embedding_766  embedding_767\n",
       "0         0.033561     0.241628  ...       0.048150      -0.006486\n",
       "1         0.003222     0.121184  ...      -0.028284      -0.059996\n",
       "2        -0.000346     0.075674  ...       0.011964      -0.043312\n",
       "3         0.055516     0.165853  ...      -0.008864      -0.007149\n",
       "4         0.005066     0.098936  ...      -0.073302      -0.077008\n",
       "...            ...          ...  ...            ...            ...\n",
       "19356     0.000859     0.190487  ...       0.012792      -0.004653\n",
       "19357     0.032032     0.061537  ...      -0.049907      -0.018135\n",
       "19358    -0.042555    -0.036387  ...       0.005990       0.029666\n",
       "19359    -0.046310     0.032858  ...      -0.032256      -0.094332\n",
       "19360     0.038412     0.145606  ...       0.047412      -0.005209\n",
       "\n",
       "[19361 rows x 768 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!c1.32\n",
    "X_best_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "cellId": "0bbn2hvikygpysaii6j7wwc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# #!c1.32\n",
    "# X_emb = generate_embeddings(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "cellId": "if27juc5h82lblxw3zfia"
   },
   "outputs": [],
   "source": [
    "# X_emb.to_csv('embedding_train_new_pymorphy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "cellId": "puened9mxlght36gkacn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "X_emb_train, X_emb_test, y_emb_train, y_emb_test = train_test_split(X_best_emb, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "cellId": "9xvkenxws7crr5urhquwl7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/catboost/core.py:966: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Define the training and validation pools\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n",
    "train_pool = Pool(X_emb_train, y_emb_train)\n",
    "val_pool = Pool(X_emb_test, y_emb_test)\n",
    "\n",
    "# Define the CatBoost classifier with CUDA\n",
    "model = CatBoostClassifier(\n",
    "    task_type='GPU',\n",
    "    devices='0:1',\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='AUC',\n",
    "    learning_rate=0.008,\n",
    "    iterations=4200,\n",
    "    depth=10,\n",
    "    verbose=100,\n",
    "    l2_leaf_reg=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "cellId": "1u6e5kqpf4aj5efthjk6x14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8532577\tbest: 0.8532577 (0)\ttotal: 74.5ms\tremaining: 5m 13s\n",
      "100:\ttest: 0.9058735\tbest: 0.9059212 (98)\ttotal: 6.62s\tremaining: 4m 28s\n",
      "200:\ttest: 0.9144675\tbest: 0.9144675 (200)\ttotal: 13.1s\tremaining: 4m 21s\n",
      "300:\ttest: 0.9210121\tbest: 0.9210121 (300)\ttotal: 19.6s\tremaining: 4m 13s\n",
      "400:\ttest: 0.9262850\tbest: 0.9262850 (400)\ttotal: 25.9s\tremaining: 4m 5s\n",
      "500:\ttest: 0.9302868\tbest: 0.9302868 (500)\ttotal: 32.2s\tremaining: 3m 57s\n",
      "600:\ttest: 0.9333210\tbest: 0.9333210 (600)\ttotal: 38.5s\tremaining: 3m 50s\n",
      "700:\ttest: 0.9356649\tbest: 0.9356649 (700)\ttotal: 44.7s\tremaining: 3m 42s\n",
      "800:\ttest: 0.9376701\tbest: 0.9376701 (800)\ttotal: 50.7s\tremaining: 3m 35s\n",
      "900:\ttest: 0.9393077\tbest: 0.9393077 (900)\ttotal: 56.6s\tremaining: 3m 27s\n",
      "1000:\ttest: 0.9405672\tbest: 0.9405672 (1000)\ttotal: 1m 2s\tremaining: 3m 20s\n",
      "1100:\ttest: 0.9415744\tbest: 0.9415744 (1100)\ttotal: 1m 8s\tremaining: 3m 12s\n",
      "1200:\ttest: 0.9424833\tbest: 0.9424833 (1200)\ttotal: 1m 14s\tremaining: 3m 5s\n",
      "1300:\ttest: 0.9431763\tbest: 0.9431772 (1299)\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "1400:\ttest: 0.9437888\tbest: 0.9437888 (1400)\ttotal: 1m 26s\tremaining: 2m 51s\n",
      "1500:\ttest: 0.9444078\tbest: 0.9444078 (1500)\ttotal: 1m 31s\tremaining: 2m 45s\n",
      "1600:\ttest: 0.9449019\tbest: 0.9449019 (1600)\ttotal: 1m 37s\tremaining: 2m 38s\n",
      "1700:\ttest: 0.9452393\tbest: 0.9452409 (1699)\ttotal: 1m 43s\tremaining: 2m 31s\n",
      "1800:\ttest: 0.9456039\tbest: 0.9456043 (1799)\ttotal: 1m 48s\tremaining: 2m 25s\n",
      "1900:\ttest: 0.9459185\tbest: 0.9459185 (1900)\ttotal: 1m 54s\tremaining: 2m 18s\n",
      "2000:\ttest: 0.9461301\tbest: 0.9461498 (1994)\ttotal: 2m\tremaining: 2m 12s\n",
      "2100:\ttest: 0.9463532\tbest: 0.9463532 (2100)\ttotal: 2m 5s\tremaining: 2m 5s\n",
      "2200:\ttest: 0.9465829\tbest: 0.9465829 (2200)\ttotal: 2m 11s\tremaining: 1m 59s\n",
      "2300:\ttest: 0.9467516\tbest: 0.9467568 (2297)\ttotal: 2m 16s\tremaining: 1m 53s\n",
      "2400:\ttest: 0.9469346\tbest: 0.9469346 (2400)\ttotal: 2m 22s\tremaining: 1m 46s\n",
      "2500:\ttest: 0.9470295\tbest: 0.9470325 (2490)\ttotal: 2m 28s\tremaining: 1m 40s\n",
      "2600:\ttest: 0.9471289\tbest: 0.9471376 (2597)\ttotal: 2m 33s\tremaining: 1m 34s\n",
      "2700:\ttest: 0.9472195\tbest: 0.9472269 (2699)\ttotal: 2m 39s\tremaining: 1m 28s\n",
      "2800:\ttest: 0.9472454\tbest: 0.9472504 (2782)\ttotal: 2m 44s\tremaining: 1m 22s\n",
      "2900:\ttest: 0.9473257\tbest: 0.9473257 (2900)\ttotal: 2m 49s\tremaining: 1m 16s\n",
      "3000:\ttest: 0.9473517\tbest: 0.9473576 (2977)\ttotal: 2m 55s\tremaining: 1m 10s\n",
      "3100:\ttest: 0.9474172\tbest: 0.9474350 (3093)\ttotal: 3m\tremaining: 1m 4s\n",
      "3200:\ttest: 0.9474639\tbest: 0.9474861 (3184)\ttotal: 3m 6s\tremaining: 58.1s\n",
      "3300:\ttest: 0.9474824\tbest: 0.9474889 (3292)\ttotal: 3m 11s\tremaining: 52.2s\n",
      "3400:\ttest: 0.9475056\tbest: 0.9475063 (3341)\ttotal: 3m 17s\tremaining: 46.3s\n",
      "3500:\ttest: 0.9475074\tbest: 0.9475154 (3471)\ttotal: 3m 22s\tremaining: 40.4s\n",
      "3600:\ttest: 0.9475116\tbest: 0.9475316 (3570)\ttotal: 3m 27s\tremaining: 34.6s\n",
      "3700:\ttest: 0.9475224\tbest: 0.9475371 (3639)\ttotal: 3m 33s\tremaining: 28.7s\n",
      "3800:\ttest: 0.9475568\tbest: 0.9475568 (3800)\ttotal: 3m 38s\tremaining: 22.9s\n",
      "3900:\ttest: 0.9475502\tbest: 0.9475645 (3851)\ttotal: 3m 43s\tremaining: 17.2s\n",
      "4000:\ttest: 0.9475575\tbest: 0.9475692 (3978)\ttotal: 3m 49s\tremaining: 11.4s\n",
      "4100:\ttest: 0.9475840\tbest: 0.9475962 (4096)\ttotal: 3m 54s\tremaining: 5.67s\n",
      "4199:\ttest: 0.9475565\tbest: 0.9475962 (4096)\ttotal: 4m\tremaining: 0us\n",
      "bestTest = 0.9475961544\n",
      "bestIteration = 4096\n",
      "Shrink model to first 4097 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f256694a3a0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "#fit the model to the data\n",
    "model.fit(train_pool, eval_set=val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "cellId": "uv17ymiou4a4ueqvaljldr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score 1200 catboost embedding+new rubert ovr:  0.9440055418417646\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print('roc_auc_score 1200 catboost embedding+new rubert ovr: ', roc_auc_score(y_emb_test, model.predict_proba(X_emb_test), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "cellId": "s2lyn6lk0tli12j39l8ax"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.save_model('best_model_catboost')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "78i9gyrt7re0ytc2yqnkavr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6pcjygzpp3yk6dk22f99qt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yp3ay89ix7p7pwilcq4zvm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mpmui5e5w3u2y4dmyfdre"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ofj0ini8qydrxzreo1w3b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "i19rcruht3artxj0vi1ina"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "hf4cqohuq6jg9f3b9uzngi"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "classifier_emb = xgb.XGBClassifier(max_depth=10, n_estimators = 800, objective='multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "yb08d6nghqg1hm9segcp7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(max_depth=10, n_estimators=800, objective='multi:softprob')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!c1.32\n",
    "classifier_emb.fit(X_emb_train, y_emb_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellId": "y8ch36g8f7ahwimqgf3e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score base xgb embedding rubert ovr:  0.9268632227997534\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "print('roc_auc_score base xgb embedding rubert ovr: ', roc_auc_score(y_emb_test, classifier_emb.predict_proba(X_emb_test), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "cellId": "u24hkrusvbncvj7un9btg"
   },
   "outputs": [],
   "source": [
    "# #!c1.32\n",
    "# model_file = \"xgb_model.bin\"\n",
    "# classifier_emb.save_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cellId": "mszkh5827cm34y269kthca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.8812439e-04, 3.0480765e-04, 9.9890709e-01],\n",
       "       [6.8348052e-04, 4.3926499e-04, 9.9887723e-01],\n",
       "       [9.9733162e-01, 2.7542564e-04, 2.3929384e-03],\n",
       "       ...,\n",
       "       [8.1660348e-04, 4.9940941e-01, 4.9977395e-01],\n",
       "       [4.2800098e-03, 9.9232894e-01, 3.3910370e-03],\n",
       "       [6.2781095e-04, 3.1640078e-04, 9.9905580e-01]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!c1.32\n",
    "classifier_emb.predict_proba(X_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "eigrkrt1f1y57qokbgk3"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cellId": "uesltqbp9uk6gcdpg5c4d"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"xgb_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cellId": "39u03cx4xxdtv6sey274mm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score base xgb embedding rubert ovr:  0.9268632227997534\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "print('roc_auc_score base xgb embedding rubert ovr: ', roc_auc_score(y_emb_test, loaded_model.predict(xgb.DMatrix(X_emb_test)), multi_class='ovr'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "d238b7b7-2642-4ae3-939c-d112e513f362",
  "notebookPath": "hse_rinat/hsehack_2023/rinat_base.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
