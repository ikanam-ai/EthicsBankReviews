{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84efb11e-22f7-4faf-baf3-6c7742f6ef07",
   "metadata": {},
   "source": [
    "## Importing the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01afcfa8-e08f-4a85-b03a-adc53e2d9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748aebeb-e756-487c-9658-0cebb22e5fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46ad655d-d570-4c03-bc7e-3b100e8de13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175996e-2dc7-448c-80ad-3a9371226f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preproc and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4ca671a-de34-4797-a822-5f9242b4c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw/1sentencenewtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18a7d8ce-494a-4faf-920b-87e61710d614",
   "metadata": {
    "_uuid": "4cc9d80f5b9969346c8f5ff24e3ce8de25dfc93d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "y43HcyWgEadG",
    "outputId": "38ac5b75-2b34-4d13-8cbf-c56739ac6d02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>949.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>274.097002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>948.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0\n",
       "count  949.000000\n",
       "mean   474.000000\n",
       "std    274.097002\n",
       "min      0.000000\n",
       "25%    237.000000\n",
       "50%    474.000000\n",
       "75%    711.000000\n",
       "max    948.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fd3b8f-2574-4885-8409-d4a5e697a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('russian')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^а-яА-Я?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b1f512-1350-4fa1-81a1-58c5a993422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b2aa37-fe23-43d4-aeb5-32c867dadcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8229275e-bc3e-42d1-9a56-43174b542973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.03.2022 обратился на горячую линию для закр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Уже который год в ТКБ не решается \"глобальная ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Добрый день</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Добрый день Сегодня, зайдя в свой личный кабин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обслуживаюсь в Тинькофф пару лет, возникла жес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Отвратительный сервис и отношение к клиентам! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>28.04.2022 обратилась в банк о возможности пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>В начале 2021 года была акция по выплате 8% ке...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Бездействие банка и некомпетентность сотрудников</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Потрачено 5 часов чтобы произвести оплату за о...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts\n",
       "0    15.03.2022 обратился на горячую линию для закр...\n",
       "1    Уже который год в ТКБ не решается \"глобальная ...\n",
       "2                                          Добрый день\n",
       "3    Добрый день Сегодня, зайдя в свой личный кабин...\n",
       "4    Обслуживаюсь в Тинькофф пару лет, возникла жес...\n",
       "..                                                 ...\n",
       "944  Отвратительный сервис и отношение к клиентам! ...\n",
       "945  28.04.2022 обратилась в банк о возможности пер...\n",
       "946  В начале 2021 года была акция по выплате 8% ке...\n",
       "947   Бездействие банка и некомпетентность сотрудников\n",
       "948  Потрачено 5 часов чтобы произвести оплату за о...\n",
       "\n",
       "[949 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4b5c77a-2e24-41e8-aa62-0de7df4b7db0",
   "metadata": {
    "_uuid": "01da38cc4626a85b73fbb526d9a8d128d1fd9338",
    "id": "baSmeDdIEadM"
   },
   "outputs": [],
   "source": [
    "new_df = train[['texts']]\n",
    "new_df['texts'] = new_df['texts'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b15abe3-8c01-4854-91d5-8ef98df6c775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "30864762e7f242c281b72862c5c08a33",
      "dd12a39995584ba79f0e786b370b1a99",
      "b89c9e76b5594a8ea601b9c5d2af4fa6",
      "f65c7649640b4e87a7819a3da2f54fe0",
      "80a6b6c9c4d5436ebe3b90b791c6fd93",
      "8c1f6e94723842faa6bd3dcd9ff4ea82",
      "39b5ca071fd3452e9d9145dd2b366da1",
      "f8dfd3ea6bb7413592115195bc6e0b83",
      "611dfdca86f4498e8aa1491ed6ffb13d",
      "be4857f17c244fb39a771f2c97283fd5",
      "2fe41e1db18b4295a6907771462a0fce",
      "0b29a9e1a275451bbc2114807532f91e",
      "115c8809853d410fac6e7f69af5a5488",
      "390827d7d2cb4b4fbfc0c022f015f7ed",
      "5d305d4db08f47ba91461edb343874a4",
      "773af3ca0add4e7cac0a036fb8b55632"
     ]
    },
    "id": "nvXxpfNCGER2",
    "outputId": "d7281fe1-0dbf-42d7-c1e0-b51c4231c9c0"
   },
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "VALID_BATCH_SIZE = 48\n",
    "VALID_BATCH_SIZE\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('ai-forever/ruRoberta-large', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e1040b3-de95-475c-a923-dddb60a31850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.texts\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9a4a8-5455-4127-8935-73803571f76e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7Gpe9D1QHoCd",
    "outputId": "7fc7fc2e-68a2-44b7-8e80-6bb6ce6c178b"
   },
   "outputs": [],
   "source": [
    "all_data_set = TestData(new_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da938e3e-1449-4d1e-88c0-2adf8770475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb_params = {'batch_size': 1,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "all_data_loader = DataLoader(all_data_set, **test_emb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "290ce7c5-cdb7-414c-a78d-a46155941e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai-forever/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "class MTnluClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MTnluClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "        self.pre_classifier = torch.nn.Linear(1024, 1024)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(1024, 3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "    \n",
    "    def get_embed(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        return pooler\n",
    "    \n",
    "model = MTnluClass()\n",
    "model.load_state_dict(torch.load('/app/hsehack_2023/models/rorubert88_n.pth', map_location='cpu'))\n",
    "model.to(device)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed8d0e57-0afa-4e57-aa04-87e91e638a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_test_data_set = TestData(new_df, tokenizer, MAX_LEN)\n",
    "test_emb_params = {'batch_size': 1,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "one_test_data_set_loader = DataLoader(one_test_data_set, **test_emb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95456427",
   "metadata": {},
   "source": [
    "## Creating embeddings for training Catboost (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd8c88b3-474d-4a91-88c4-c87e2b01deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "949it [00:15, 61.95it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs_all = []\n",
    "targets_all = []\n",
    "with torch.no_grad():\n",
    "    for _,data in tqdm(enumerate(one_test_data_set_loader)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        embed = model.get_embed(ids, mask, token_type_ids)\n",
    "        outputs_all += embed.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84d0c25f-d95b-4f7f-8cca-7a9469076d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902784</td>\n",
       "      <td>1.297987</td>\n",
       "      <td>1.097821</td>\n",
       "      <td>0.473421</td>\n",
       "      <td>1.317624</td>\n",
       "      <td>-0.386039</td>\n",
       "      <td>-0.650004</td>\n",
       "      <td>0.352344</td>\n",
       "      <td>-1.403260</td>\n",
       "      <td>-0.897125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226840</td>\n",
       "      <td>1.308397</td>\n",
       "      <td>0.352750</td>\n",
       "      <td>1.283166</td>\n",
       "      <td>0.345595</td>\n",
       "      <td>-1.013453</td>\n",
       "      <td>-0.267477</td>\n",
       "      <td>1.366219</td>\n",
       "      <td>0.117605</td>\n",
       "      <td>-0.537010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944837</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.572766</td>\n",
       "      <td>1.070573</td>\n",
       "      <td>0.882211</td>\n",
       "      <td>0.149938</td>\n",
       "      <td>-0.545597</td>\n",
       "      <td>-0.353828</td>\n",
       "      <td>-0.057254</td>\n",
       "      <td>0.895224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475763</td>\n",
       "      <td>-0.490487</td>\n",
       "      <td>-0.670113</td>\n",
       "      <td>1.174313</td>\n",
       "      <td>-0.529262</td>\n",
       "      <td>-0.447935</td>\n",
       "      <td>0.400307</td>\n",
       "      <td>0.223325</td>\n",
       "      <td>-0.919455</td>\n",
       "      <td>0.124954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.796639</td>\n",
       "      <td>1.319802</td>\n",
       "      <td>1.337188</td>\n",
       "      <td>1.457283</td>\n",
       "      <td>-0.419512</td>\n",
       "      <td>-1.532776</td>\n",
       "      <td>-1.176540</td>\n",
       "      <td>-0.290054</td>\n",
       "      <td>-0.172236</td>\n",
       "      <td>-0.272150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403010</td>\n",
       "      <td>0.322864</td>\n",
       "      <td>0.691736</td>\n",
       "      <td>1.032278</td>\n",
       "      <td>0.096567</td>\n",
       "      <td>-0.375766</td>\n",
       "      <td>0.334493</td>\n",
       "      <td>1.567537</td>\n",
       "      <td>-0.823011</td>\n",
       "      <td>-0.217747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.275302</td>\n",
       "      <td>0.918977</td>\n",
       "      <td>1.185814</td>\n",
       "      <td>1.794785</td>\n",
       "      <td>0.934858</td>\n",
       "      <td>-0.178377</td>\n",
       "      <td>-1.075327</td>\n",
       "      <td>-0.810617</td>\n",
       "      <td>-0.653230</td>\n",
       "      <td>0.612582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195291</td>\n",
       "      <td>0.156671</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.962776</td>\n",
       "      <td>-0.394968</td>\n",
       "      <td>-0.453509</td>\n",
       "      <td>0.663603</td>\n",
       "      <td>0.394088</td>\n",
       "      <td>-1.177859</td>\n",
       "      <td>0.548877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.793053</td>\n",
       "      <td>0.351079</td>\n",
       "      <td>0.368790</td>\n",
       "      <td>-0.409059</td>\n",
       "      <td>0.174641</td>\n",
       "      <td>-2.175166</td>\n",
       "      <td>0.631875</td>\n",
       "      <td>0.475518</td>\n",
       "      <td>-0.590075</td>\n",
       "      <td>-0.857128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135209</td>\n",
       "      <td>0.281186</td>\n",
       "      <td>0.527828</td>\n",
       "      <td>1.498899</td>\n",
       "      <td>0.140249</td>\n",
       "      <td>-0.097825</td>\n",
       "      <td>-0.085177</td>\n",
       "      <td>1.868248</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>-0.696183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.369200</td>\n",
       "      <td>0.948618</td>\n",
       "      <td>0.673172</td>\n",
       "      <td>0.967206</td>\n",
       "      <td>0.485682</td>\n",
       "      <td>0.090520</td>\n",
       "      <td>-1.017609</td>\n",
       "      <td>-0.299503</td>\n",
       "      <td>-0.744506</td>\n",
       "      <td>0.155051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279977</td>\n",
       "      <td>-1.034256</td>\n",
       "      <td>-0.305458</td>\n",
       "      <td>1.236149</td>\n",
       "      <td>-0.485411</td>\n",
       "      <td>-0.403664</td>\n",
       "      <td>1.283632</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>-0.377079</td>\n",
       "      <td>0.035251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>-1.247719</td>\n",
       "      <td>0.991658</td>\n",
       "      <td>0.270783</td>\n",
       "      <td>0.428659</td>\n",
       "      <td>0.860768</td>\n",
       "      <td>-1.100553</td>\n",
       "      <td>-0.312232</td>\n",
       "      <td>1.169824</td>\n",
       "      <td>-0.932231</td>\n",
       "      <td>-0.079898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082377</td>\n",
       "      <td>0.539750</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.697156</td>\n",
       "      <td>0.158279</td>\n",
       "      <td>-0.720043</td>\n",
       "      <td>0.056121</td>\n",
       "      <td>1.879779</td>\n",
       "      <td>-0.028113</td>\n",
       "      <td>-0.078348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>-1.820407</td>\n",
       "      <td>0.242353</td>\n",
       "      <td>0.623281</td>\n",
       "      <td>0.288891</td>\n",
       "      <td>0.490508</td>\n",
       "      <td>-1.459233</td>\n",
       "      <td>-0.269929</td>\n",
       "      <td>-0.344785</td>\n",
       "      <td>-0.662301</td>\n",
       "      <td>-0.942734</td>\n",
       "      <td>...</td>\n",
       "      <td>1.397328</td>\n",
       "      <td>-0.040501</td>\n",
       "      <td>0.674187</td>\n",
       "      <td>0.562148</td>\n",
       "      <td>0.199344</td>\n",
       "      <td>-0.023411</td>\n",
       "      <td>-0.075049</td>\n",
       "      <td>1.775784</td>\n",
       "      <td>-0.020173</td>\n",
       "      <td>-0.500412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.800777</td>\n",
       "      <td>0.432450</td>\n",
       "      <td>0.663991</td>\n",
       "      <td>1.563629</td>\n",
       "      <td>0.178798</td>\n",
       "      <td>-0.084471</td>\n",
       "      <td>-0.484259</td>\n",
       "      <td>-0.209525</td>\n",
       "      <td>-0.471602</td>\n",
       "      <td>0.368284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387483</td>\n",
       "      <td>-0.284803</td>\n",
       "      <td>0.038228</td>\n",
       "      <td>1.723029</td>\n",
       "      <td>-0.493063</td>\n",
       "      <td>-1.122302</td>\n",
       "      <td>0.487029</td>\n",
       "      <td>0.663240</td>\n",
       "      <td>-0.910323</td>\n",
       "      <td>0.367088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.709736</td>\n",
       "      <td>0.258829</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>1.970540</td>\n",
       "      <td>0.262219</td>\n",
       "      <td>-0.631261</td>\n",
       "      <td>0.822294</td>\n",
       "      <td>1.542598</td>\n",
       "      <td>0.181307</td>\n",
       "      <td>-0.048057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883348</td>\n",
       "      <td>1.068971</td>\n",
       "      <td>-0.338139</td>\n",
       "      <td>-0.071605</td>\n",
       "      <td>-0.930004</td>\n",
       "      <td>-0.125148</td>\n",
       "      <td>-1.646377</td>\n",
       "      <td>0.806695</td>\n",
       "      <td>-0.671737</td>\n",
       "      <td>0.003218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0   -0.902784  1.297987  1.097821  0.473421  1.317624 -0.386039 -0.650004   \n",
       "1    0.944837  0.068766  0.572766  1.070573  0.882211  0.149938 -0.545597   \n",
       "2    0.796639  1.319802  1.337188  1.457283 -0.419512 -1.532776 -1.176540   \n",
       "3    1.275302  0.918977  1.185814  1.794785  0.934858 -0.178377 -1.075327   \n",
       "4   -0.793053  0.351079  0.368790 -0.409059  0.174641 -2.175166  0.631875   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "944  0.369200  0.948618  0.673172  0.967206  0.485682  0.090520 -1.017609   \n",
       "945 -1.247719  0.991658  0.270783  0.428659  0.860768 -1.100553 -0.312232   \n",
       "946 -1.820407  0.242353  0.623281  0.288891  0.490508 -1.459233 -0.269929   \n",
       "947  0.800777  0.432450  0.663991  1.563629  0.178798 -0.084471 -0.484259   \n",
       "948  0.709736  0.258829  0.002631  1.970540  0.262219 -0.631261  0.822294   \n",
       "\n",
       "         7         8         9     ...      1014      1015      1016  \\\n",
       "0    0.352344 -1.403260 -0.897125  ...  0.226840  1.308397  0.352750   \n",
       "1   -0.353828 -0.057254  0.895224  ...  0.475763 -0.490487 -0.670113   \n",
       "2   -0.290054 -0.172236 -0.272150  ... -0.403010  0.322864  0.691736   \n",
       "3   -0.810617 -0.653230  0.612582  ...  0.195291  0.156671  0.038190   \n",
       "4    0.475518 -0.590075 -0.857128  ...  0.135209  0.281186  0.527828   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "944 -0.299503 -0.744506  0.155051  ...  0.279977 -1.034256 -0.305458   \n",
       "945  1.169824 -0.932231 -0.079898  ... -0.082377  0.539750  0.937748   \n",
       "946 -0.344785 -0.662301 -0.942734  ...  1.397328 -0.040501  0.674187   \n",
       "947 -0.209525 -0.471602  0.368284  ...  0.387483 -0.284803  0.038228   \n",
       "948  1.542598  0.181307 -0.048057  ...  0.883348  1.068971 -0.338139   \n",
       "\n",
       "         1017      1018      1019      1020      1021      1022      1023  \n",
       "0    1.283166  0.345595 -1.013453 -0.267477  1.366219  0.117605 -0.537010  \n",
       "1    1.174313 -0.529262 -0.447935  0.400307  0.223325 -0.919455  0.124954  \n",
       "2    1.032278  0.096567 -0.375766  0.334493  1.567537 -0.823011 -0.217747  \n",
       "3    0.962776 -0.394968 -0.453509  0.663603  0.394088 -1.177859  0.548877  \n",
       "4    1.498899  0.140249 -0.097825 -0.085177  1.868248  0.258400 -0.696183  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "944  1.236149 -0.485411 -0.403664  1.283632  0.009503 -0.377079  0.035251  \n",
       "945  0.697156  0.158279 -0.720043  0.056121  1.879779 -0.028113 -0.078348  \n",
       "946  0.562148  0.199344 -0.023411 -0.075049  1.775784 -0.020173 -0.500412  \n",
       "947  1.723029 -0.493063 -1.122302  0.487029  0.663240 -0.910323  0.367088  \n",
       "948 -0.071605 -0.930004 -0.125148 -1.646377  0.806695 -0.671737  0.003218  \n",
       "\n",
       "[949 rows x 1024 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe8ff5a4-bf29-485c-b6af-14ec5664abed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "949it [00:16, 58.35it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs_all = []\n",
    "targets_all = []\n",
    "with torch.no_grad():\n",
    "    for _,data in tqdm(enumerate(all_data_loader)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        embed = model.get_embed(ids, mask, token_type_ids)\n",
    "        outputs_all += embed.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e62874e8-16df-4d7a-b3b5-1a6005a1e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = pd.DataFrame(outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2756ad50-b260-4ec0-be2d-e43af353b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb.to_csv('result_test_sent_true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2101738a-b806-49b1-9cdc-61fc3d546cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
