{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f25fe6e",
   "metadata": {},
   "source": [
    "## Importing the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bb3e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8808fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e017a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19957dab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preproc and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34ec8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw/1sentencenewtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "826c53c8",
   "metadata": {
    "_uuid": "4cc9d80f5b9969346c8f5ff24e3ce8de25dfc93d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "y43HcyWgEadG",
    "outputId": "38ac5b75-2b34-4d13-8cbf-c56739ac6d02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>949.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>274.097002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>948.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0\n",
       "count  949.000000\n",
       "mean   474.000000\n",
       "std    274.097002\n",
       "min      0.000000\n",
       "25%    237.000000\n",
       "50%    474.000000\n",
       "75%    711.000000\n",
       "max    948.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40ca69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('russian')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^а-яА-Я?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9eeb7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.03.2022 обратился на горячую линию для закр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Уже который год в ТКБ не решается \"глобальная ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Добрый день</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Добрый день Сегодня, зайдя в свой личный кабин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Обслуживаюсь в Тинькофф пару лет, возникла жес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>Отвратительный сервис и отношение к клиентам! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>28.04.2022 обратилась в банк о возможности пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>В начале 2021 года была акция по выплате 8% ке...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>947</td>\n",
       "      <td>Бездействие банка и некомпетентность сотрудников</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>948</td>\n",
       "      <td>Потрачено 5 часов чтобы произвести оплату за о...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                  0\n",
       "0             0  15.03.2022 обратился на горячую линию для закр...\n",
       "1             1  Уже который год в ТКБ не решается \"глобальная ...\n",
       "2             2                                        Добрый день\n",
       "3             3  Добрый день Сегодня, зайдя в свой личный кабин...\n",
       "4             4  Обслуживаюсь в Тинькофф пару лет, возникла жес...\n",
       "..          ...                                                ...\n",
       "944         944  Отвратительный сервис и отношение к клиентам! ...\n",
       "945         945  28.04.2022 обратилась в банк о возможности пер...\n",
       "946         946  В начале 2021 года была акция по выплате 8% ке...\n",
       "947         947   Бездействие банка и некомпетентность сотрудников\n",
       "948         948  Потрачено 5 часов чтобы произвести оплату за о...\n",
       "\n",
       "[949 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d746318",
   "metadata": {
    "_uuid": "01da38cc4626a85b73fbb526d9a8d128d1fd9338",
    "id": "baSmeDdIEadM"
   },
   "outputs": [],
   "source": [
    "train = train[['0']]\n",
    "train.columns = ['texts']\n",
    "new_df = train[['texts']]\n",
    "new_df['texts'] = new_df['texts'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2425adc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "30864762e7f242c281b72862c5c08a33",
      "dd12a39995584ba79f0e786b370b1a99",
      "b89c9e76b5594a8ea601b9c5d2af4fa6",
      "f65c7649640b4e87a7819a3da2f54fe0",
      "80a6b6c9c4d5436ebe3b90b791c6fd93",
      "8c1f6e94723842faa6bd3dcd9ff4ea82",
      "39b5ca071fd3452e9d9145dd2b366da1",
      "f8dfd3ea6bb7413592115195bc6e0b83",
      "611dfdca86f4498e8aa1491ed6ffb13d",
      "be4857f17c244fb39a771f2c97283fd5",
      "2fe41e1db18b4295a6907771462a0fce",
      "0b29a9e1a275451bbc2114807532f91e",
      "115c8809853d410fac6e7f69af5a5488",
      "390827d7d2cb4b4fbfc0c022f015f7ed",
      "5d305d4db08f47ba91461edb343874a4",
      "773af3ca0add4e7cac0a036fb8b55632"
     ]
    },
    "id": "nvXxpfNCGER2",
    "outputId": "d7281fe1-0dbf-42d7-c1e0-b51c4231c9c0"
   },
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "VALID_BATCH_SIZE = 48\n",
    "VALID_BATCH_SIZE\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('ai-forever/ruRoberta-large', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b9412eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.texts\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582069a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7Gpe9D1QHoCd",
    "outputId": "7fc7fc2e-68a2-44b7-8e80-6bb6ce6c178b"
   },
   "outputs": [],
   "source": [
    "all_data_set = TestData(new_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9814caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb_params = {'batch_size': 1,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0ce456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_loader = DataLoader(all_data_set, **test_emb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f3332",
   "metadata": {
    "tags": []
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52b8be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai-forever/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "class MTnluClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MTnluClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "        self.pre_classifier = torch.nn.Linear(1024, 1024)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(1024, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "    \n",
    "    def get_embed(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        return pooler\n",
    "    \n",
    "model = MTnluClass()\n",
    "model.load_state_dict(torch.load('/app/hsehack_2023/models/rorubert69_CAT.pth', map_location='cpu'))\n",
    "model.to(device)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6942bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "LEARNING_RATE = 1e-05\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48f15990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc_auc(preds, targets):\n",
    "    # proba_dict = {0:np.array([1.,0.,0.]),\n",
    "    #               1:np.array([0.,1.,0.]),\n",
    "    #               2:np.array([0.,0.,1.])}\n",
    "    # targets = np.array(list(map(lambda x: proba_dict[x], targets.cpu().numpy())))\n",
    "    # preds = np.array(list(map(lambda x: proba_dict[x], preds.cpu().numpy())))\n",
    "    # print(preds)\n",
    "    # print(targets)\n",
    "    y_preds = label_binarize(preds.cpu().numpy(), classes=[0,1,2])\n",
    "    return roc_auc_score(y_preds, targets.cpu().numpy(), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2bc7b",
   "metadata": {},
   "source": [
    "## get embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5e346c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "949it [00:24, 38.58it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs_all = []\n",
    "targets_all = []\n",
    "with torch.no_grad():\n",
    "    for _,data in tqdm(enumerate(all_data_loader)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        embed = model.get_embed(ids, mask, token_type_ids)\n",
    "        outputs_all += embed.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58c24ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = pd.DataFrame(outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "351cc910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.105424</td>\n",
       "      <td>-0.029983</td>\n",
       "      <td>1.804730</td>\n",
       "      <td>0.464423</td>\n",
       "      <td>-0.169759</td>\n",
       "      <td>0.758372</td>\n",
       "      <td>0.648669</td>\n",
       "      <td>1.030470</td>\n",
       "      <td>0.312744</td>\n",
       "      <td>-0.562729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460382</td>\n",
       "      <td>-0.230731</td>\n",
       "      <td>-0.253761</td>\n",
       "      <td>1.402969</td>\n",
       "      <td>0.640821</td>\n",
       "      <td>0.191719</td>\n",
       "      <td>0.217602</td>\n",
       "      <td>-0.054679</td>\n",
       "      <td>-0.569984</td>\n",
       "      <td>-0.195901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021426</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.824718</td>\n",
       "      <td>0.305604</td>\n",
       "      <td>0.727099</td>\n",
       "      <td>1.256473</td>\n",
       "      <td>0.539974</td>\n",
       "      <td>1.645575</td>\n",
       "      <td>-0.322572</td>\n",
       "      <td>-0.148913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033642</td>\n",
       "      <td>0.592735</td>\n",
       "      <td>-0.066000</td>\n",
       "      <td>0.577592</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.470499</td>\n",
       "      <td>-0.566479</td>\n",
       "      <td>0.434932</td>\n",
       "      <td>0.427349</td>\n",
       "      <td>-0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324814</td>\n",
       "      <td>0.035358</td>\n",
       "      <td>2.206734</td>\n",
       "      <td>1.183492</td>\n",
       "      <td>-0.400563</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.161001</td>\n",
       "      <td>0.089501</td>\n",
       "      <td>0.916523</td>\n",
       "      <td>-0.431724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048207</td>\n",
       "      <td>-0.079259</td>\n",
       "      <td>0.851949</td>\n",
       "      <td>1.619860</td>\n",
       "      <td>1.704702</td>\n",
       "      <td>0.129969</td>\n",
       "      <td>0.121547</td>\n",
       "      <td>-0.124396</td>\n",
       "      <td>-0.071353</td>\n",
       "      <td>-0.024287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.626395</td>\n",
       "      <td>0.252436</td>\n",
       "      <td>1.275309</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>0.921104</td>\n",
       "      <td>0.421728</td>\n",
       "      <td>-0.036197</td>\n",
       "      <td>1.101363</td>\n",
       "      <td>0.866821</td>\n",
       "      <td>-0.201999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728560</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.526804</td>\n",
       "      <td>0.907070</td>\n",
       "      <td>0.436407</td>\n",
       "      <td>0.244496</td>\n",
       "      <td>0.154220</td>\n",
       "      <td>-0.450410</td>\n",
       "      <td>-0.661164</td>\n",
       "      <td>-0.126389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.411529</td>\n",
       "      <td>0.153146</td>\n",
       "      <td>0.719210</td>\n",
       "      <td>-0.219197</td>\n",
       "      <td>0.055934</td>\n",
       "      <td>0.576629</td>\n",
       "      <td>0.351966</td>\n",
       "      <td>1.051119</td>\n",
       "      <td>0.997267</td>\n",
       "      <td>-0.194857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211627</td>\n",
       "      <td>0.061256</td>\n",
       "      <td>0.550845</td>\n",
       "      <td>0.460794</td>\n",
       "      <td>-0.345221</td>\n",
       "      <td>0.602286</td>\n",
       "      <td>-0.506242</td>\n",
       "      <td>1.024468</td>\n",
       "      <td>1.414754</td>\n",
       "      <td>0.059959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.022085</td>\n",
       "      <td>-0.134628</td>\n",
       "      <td>0.899856</td>\n",
       "      <td>0.473601</td>\n",
       "      <td>-0.058273</td>\n",
       "      <td>0.502134</td>\n",
       "      <td>0.053399</td>\n",
       "      <td>0.867759</td>\n",
       "      <td>0.758415</td>\n",
       "      <td>-0.190501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310579</td>\n",
       "      <td>0.657822</td>\n",
       "      <td>0.248714</td>\n",
       "      <td>0.548124</td>\n",
       "      <td>0.794550</td>\n",
       "      <td>0.610424</td>\n",
       "      <td>0.038128</td>\n",
       "      <td>-0.080167</td>\n",
       "      <td>0.643243</td>\n",
       "      <td>-0.129744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.377225</td>\n",
       "      <td>0.457951</td>\n",
       "      <td>1.539207</td>\n",
       "      <td>0.436627</td>\n",
       "      <td>0.772954</td>\n",
       "      <td>1.523339</td>\n",
       "      <td>0.307820</td>\n",
       "      <td>0.926620</td>\n",
       "      <td>0.326569</td>\n",
       "      <td>-0.045936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176585</td>\n",
       "      <td>-1.293137</td>\n",
       "      <td>-0.180391</td>\n",
       "      <td>0.747121</td>\n",
       "      <td>-0.035019</td>\n",
       "      <td>0.192736</td>\n",
       "      <td>-0.775966</td>\n",
       "      <td>0.113963</td>\n",
       "      <td>0.554274</td>\n",
       "      <td>-0.390376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.278895</td>\n",
       "      <td>-0.677258</td>\n",
       "      <td>1.518457</td>\n",
       "      <td>1.458838</td>\n",
       "      <td>1.204773</td>\n",
       "      <td>0.896946</td>\n",
       "      <td>0.451350</td>\n",
       "      <td>0.319609</td>\n",
       "      <td>0.630101</td>\n",
       "      <td>-0.010940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>-1.128981</td>\n",
       "      <td>-0.103006</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>-1.477037</td>\n",
       "      <td>-0.204174</td>\n",
       "      <td>-1.104696</td>\n",
       "      <td>1.513376</td>\n",
       "      <td>1.225346</td>\n",
       "      <td>0.363850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>-0.089570</td>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.439491</td>\n",
       "      <td>0.759646</td>\n",
       "      <td>0.201833</td>\n",
       "      <td>0.459167</td>\n",
       "      <td>0.739456</td>\n",
       "      <td>0.605382</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>-0.026076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102963</td>\n",
       "      <td>0.880153</td>\n",
       "      <td>0.285767</td>\n",
       "      <td>0.732744</td>\n",
       "      <td>0.982480</td>\n",
       "      <td>0.100637</td>\n",
       "      <td>0.417203</td>\n",
       "      <td>-0.265152</td>\n",
       "      <td>0.309159</td>\n",
       "      <td>0.016138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.094847</td>\n",
       "      <td>-0.989143</td>\n",
       "      <td>0.173963</td>\n",
       "      <td>1.392158</td>\n",
       "      <td>0.566849</td>\n",
       "      <td>0.876018</td>\n",
       "      <td>0.550924</td>\n",
       "      <td>1.001516</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.079678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590101</td>\n",
       "      <td>0.074933</td>\n",
       "      <td>-0.024241</td>\n",
       "      <td>-0.353239</td>\n",
       "      <td>-0.369332</td>\n",
       "      <td>1.622152</td>\n",
       "      <td>-0.751965</td>\n",
       "      <td>0.555160</td>\n",
       "      <td>1.692589</td>\n",
       "      <td>-0.286763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0   -0.105424 -0.029983  1.804730  0.464423 -0.169759  0.758372  0.648669   \n",
       "1    0.021426  0.097600  0.824718  0.305604  0.727099  1.256473  0.539974   \n",
       "2    0.324814  0.035358  2.206734  1.183492 -0.400563  0.018054  0.161001   \n",
       "3   -0.626395  0.252436  1.275309  0.042013  0.921104  0.421728 -0.036197   \n",
       "4   -0.411529  0.153146  0.719210 -0.219197  0.055934  0.576629  0.351966   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "944  0.022085 -0.134628  0.899856  0.473601 -0.058273  0.502134  0.053399   \n",
       "945  0.377225  0.457951  1.539207  0.436627  0.772954  1.523339  0.307820   \n",
       "946  0.278895 -0.677258  1.518457  1.458838  1.204773  0.896946  0.451350   \n",
       "947 -0.089570  0.231045  0.439491  0.759646  0.201833  0.459167  0.739456   \n",
       "948  0.094847 -0.989143  0.173963  1.392158  0.566849  0.876018  0.550924   \n",
       "\n",
       "         7         8         9     ...      1014      1015      1016  \\\n",
       "0    1.030470  0.312744 -0.562729  ...  0.460382 -0.230731 -0.253761   \n",
       "1    1.645575 -0.322572 -0.148913  ...  0.033642  0.592735 -0.066000   \n",
       "2    0.089501  0.916523 -0.431724  ...  0.048207 -0.079259  0.851949   \n",
       "3    1.101363  0.866821 -0.201999  ... -0.728560  0.064300  0.526804   \n",
       "4    1.051119  0.997267 -0.194857  ... -0.211627  0.061256  0.550845   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "944  0.867759  0.758415 -0.190501  ... -0.310579  0.657822  0.248714   \n",
       "945  0.926620  0.326569 -0.045936  ...  0.176585 -1.293137 -0.180391   \n",
       "946  0.319609  0.630101 -0.010940  ...  0.031515 -1.128981 -0.103006   \n",
       "947  0.605382  0.020604 -0.026076  ...  0.102963  0.880153  0.285767   \n",
       "948  1.001516  0.062164  0.079678  ...  0.590101  0.074933 -0.024241   \n",
       "\n",
       "         1017      1018      1019      1020      1021      1022      1023  \n",
       "0    1.402969  0.640821  0.191719  0.217602 -0.054679 -0.569984 -0.195901  \n",
       "1    0.577592  0.541111  0.470499 -0.566479  0.434932  0.427349 -0.008582  \n",
       "2    1.619860  1.704702  0.129969  0.121547 -0.124396 -0.071353 -0.024287  \n",
       "3    0.907070  0.436407  0.244496  0.154220 -0.450410 -0.661164 -0.126389  \n",
       "4    0.460794 -0.345221  0.602286 -0.506242  1.024468  1.414754  0.059959  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "944  0.548124  0.794550  0.610424  0.038128 -0.080167  0.643243 -0.129744  \n",
       "945  0.747121 -0.035019  0.192736 -0.775966  0.113963  0.554274 -0.390376  \n",
       "946  0.022389 -1.477037 -0.204174 -1.104696  1.513376  1.225346  0.363850  \n",
       "947  0.732744  0.982480  0.100637  0.417203 -0.265152  0.309159  0.016138  \n",
       "948 -0.353239 -0.369332  1.622152 -0.751965  0.555160  1.692589 -0.286763  \n",
       "\n",
       "[949 rows x 1024 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "904019b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb.to_csv('test_emb_cat_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0095033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
